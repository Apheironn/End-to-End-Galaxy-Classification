{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1efd1125",
   "metadata": {
    "colab_type": "text",
    "id": "3DR-eO17geWu"
   },
   "source": [
    "# Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4824ecb4",
   "metadata": {
    "colab_type": "text",
    "id": "EMefrVPCg-60"
   },
   "source": [
    "### Importing the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "12960011",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sCV30xyVhFbE"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c7a0b9a1",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FIleuCAjoFD8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.10.0'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fdccbdf",
   "metadata": {
    "colab_type": "text",
    "id": "oxQxCBWyoGPE"
   },
   "source": [
    "## Part 1 - Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c56b78d",
   "metadata": {
    "colab_type": "text",
    "id": "MvE-heJNo3GG"
   },
   "source": [
    "### Preprocessing the Training set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79f00ccc",
   "metadata": {
    "colab_type": "text",
    "id": "mrCMmGw9pHys"
   },
   "source": [
    "### Preprocessing the Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c5b34bac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 23037 images belonging to 5 classes.\n",
      "Found 5756 images belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
    "                                   shear_range = 0.2,\n",
    "                                   zoom_range = 0.2,\n",
    "                                   rotation_range=20,\n",
    "                                   width_shift_range=0.2,\n",
    "                                   height_shift_range=0.2,\n",
    "                                   horizontal_flip = True,\n",
    "                                   validation_split=0.2)  # val 20%\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255, validation_split=0.2)\n",
    "\n",
    "train_path = \"Train_images\"\n",
    "train_set = train_datagen.flow_from_directory(train_path, \n",
    "                                               target_size=(224, 224), \n",
    "                                               color_mode='rgb',\n",
    "                                               batch_size=32, \n",
    "                                               class_mode='categorical',\n",
    "                                               shuffle=True,\n",
    "                                               subset = 'training') \n",
    "\n",
    "test_set = test_datagen.flow_from_directory(train_path, \n",
    "                                           target_size=(224, 224), \n",
    "                                           color_mode='rgb',\n",
    "                                           batch_size=32, \n",
    "                                           class_mode='categorical',\n",
    "                                           shuffle=False,\n",
    "                                           subset = 'validation')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e42885f5",
   "metadata": {
    "colab_type": "text",
    "id": "af8O4l90gk7B"
   },
   "source": [
    "## Part 2 - Building the CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c540a04",
   "metadata": {
    "colab_type": "text",
    "id": "ces1gXY2lmoX"
   },
   "source": [
    "### Initialising the CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "951b1bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras.layers as layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "cab7d915",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "24196476",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn = tf.keras.models.Sequential([\n",
    "    Conv2D(64, (3, 3), activation='relu', input_shape=(224, 224, 3)),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(128, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(256, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(512, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Flatten(),\n",
    "    Dense(512, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(5, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "e8b89845",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_9 (Conv2D)           (None, 222, 222, 64)      1792      \n",
      "                                                                 \n",
      " max_pooling2d_9 (MaxPooling  (None, 111, 111, 64)     0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_10 (Conv2D)          (None, 109, 109, 128)     73856     \n",
      "                                                                 \n",
      " max_pooling2d_10 (MaxPoolin  (None, 54, 54, 128)      0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_11 (Conv2D)          (None, 52, 52, 256)       295168    \n",
      "                                                                 \n",
      " max_pooling2d_11 (MaxPoolin  (None, 26, 26, 256)      0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_12 (Conv2D)          (None, 24, 24, 512)       1180160   \n",
      "                                                                 \n",
      " max_pooling2d_12 (MaxPoolin  (None, 12, 12, 512)      0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_3 (Flatten)         (None, 73728)             0         \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 512)               37749248  \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 256)               131328    \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 5)                 1285      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 39,432,837\n",
      "Trainable params: 39,432,837\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "cnn.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d930888b",
   "metadata": {
    "colab_type": "text",
    "id": "D6XkI90snSDl"
   },
   "source": [
    "## Part 3 - Training the CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c1f8f3f",
   "metadata": {
    "colab_type": "text",
    "id": "vfrFQACEnc6i"
   },
   "source": [
    "### Compiling the CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "9b5095b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c21b5c0",
   "metadata": {
    "colab_type": "text",
    "id": "ehS-v3MIpX2h"
   },
   "source": [
    "### Training the CNN on the Training set and evaluating it on the Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "2e8fcede",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "log_dir = \"logs\"  # Replace with your preferred directory\n",
    "tensorboard_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "f8990e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "# Define your model\n",
    "\n",
    "# Define callbacks\n",
    "checkpoint = ModelCheckpoint(\"best_model.h5\", monitor=\"val_loss\", save_best_only=True)\n",
    "early_stopping = EarlyStopping(monitor=\"val_loss\", patience=10, restore_best_weights=True)\n",
    "reduce_lr = ReduceLROnPlateau(monitor=\"val_loss\", factor=0.2, patience=5, min_lr=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "ea7cd3c8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/250\n",
      "720/720 [==============================] - 174s 241ms/step - loss: 0.4256 - accuracy: 0.8394 - val_loss: 0.3361 - val_accuracy: 0.8706 - lr: 0.0010\n",
      "Epoch 2/250\n",
      "720/720 [==============================] - 170s 236ms/step - loss: 0.4160 - accuracy: 0.8452 - val_loss: 0.3276 - val_accuracy: 0.8737 - lr: 0.0010\n",
      "Epoch 3/250\n",
      "720/720 [==============================] - 171s 237ms/step - loss: 0.4168 - accuracy: 0.8436 - val_loss: 0.3359 - val_accuracy: 0.8805 - lr: 0.0010\n",
      "Epoch 4/250\n",
      "720/720 [==============================] - 172s 238ms/step - loss: 0.4138 - accuracy: 0.8466 - val_loss: 0.3514 - val_accuracy: 0.8678 - lr: 0.0010\n",
      "Epoch 5/250\n",
      "720/720 [==============================] - 171s 237ms/step - loss: 0.4009 - accuracy: 0.8541 - val_loss: 0.3208 - val_accuracy: 0.8862 - lr: 0.0010\n",
      "Epoch 6/250\n",
      "720/720 [==============================] - 174s 241ms/step - loss: 0.4039 - accuracy: 0.8501 - val_loss: 0.2983 - val_accuracy: 0.8876 - lr: 0.0010\n",
      "Epoch 7/250\n",
      "720/720 [==============================] - 171s 238ms/step - loss: 0.3921 - accuracy: 0.8545 - val_loss: 0.3109 - val_accuracy: 0.8758 - lr: 0.0010\n",
      "Epoch 8/250\n",
      "720/720 [==============================] - 172s 239ms/step - loss: 0.3920 - accuracy: 0.8516 - val_loss: 0.3171 - val_accuracy: 0.8827 - lr: 0.0010\n",
      "Epoch 9/250\n",
      "720/720 [==============================] - 171s 237ms/step - loss: 0.3908 - accuracy: 0.8568 - val_loss: 0.2816 - val_accuracy: 0.8956 - lr: 0.0010\n",
      "Epoch 10/250\n",
      "720/720 [==============================] - 175s 242ms/step - loss: 0.3815 - accuracy: 0.8588 - val_loss: 0.2709 - val_accuracy: 0.9011 - lr: 0.0010\n",
      "Epoch 11/250\n",
      "720/720 [==============================] - 174s 241ms/step - loss: 0.3877 - accuracy: 0.8576 - val_loss: 0.2840 - val_accuracy: 0.8904 - lr: 0.0010\n",
      "Epoch 12/250\n",
      "720/720 [==============================] - 174s 241ms/step - loss: 0.3866 - accuracy: 0.8550 - val_loss: 0.3113 - val_accuracy: 0.8796 - lr: 0.0010\n",
      "Epoch 13/250\n",
      "720/720 [==============================] - 173s 241ms/step - loss: 0.3793 - accuracy: 0.8581 - val_loss: 0.2913 - val_accuracy: 0.8862 - lr: 0.0010\n",
      "Epoch 14/250\n",
      "720/720 [==============================] - 174s 241ms/step - loss: 0.3796 - accuracy: 0.8587 - val_loss: 0.3097 - val_accuracy: 0.8822 - lr: 0.0010\n",
      "Epoch 15/250\n",
      "720/720 [==============================] - 174s 241ms/step - loss: 0.3780 - accuracy: 0.8581 - val_loss: 0.3054 - val_accuracy: 0.8883 - lr: 0.0010\n",
      "Epoch 16/250\n",
      "720/720 [==============================] - 175s 243ms/step - loss: 0.3319 - accuracy: 0.8763 - val_loss: 0.2557 - val_accuracy: 0.9015 - lr: 2.0000e-04\n",
      "Epoch 17/250\n",
      "720/720 [==============================] - 173s 240ms/step - loss: 0.3232 - accuracy: 0.8771 - val_loss: 0.2418 - val_accuracy: 0.9077 - lr: 2.0000e-04\n",
      "Epoch 18/250\n",
      "720/720 [==============================] - 169s 235ms/step - loss: 0.3203 - accuracy: 0.8815 - val_loss: 0.2429 - val_accuracy: 0.9064 - lr: 2.0000e-04\n",
      "Epoch 19/250\n",
      "720/720 [==============================] - 170s 235ms/step - loss: 0.3060 - accuracy: 0.8853 - val_loss: 0.2536 - val_accuracy: 0.8972 - lr: 2.0000e-04\n",
      "Epoch 20/250\n",
      "720/720 [==============================] - 170s 235ms/step - loss: 0.3140 - accuracy: 0.8816 - val_loss: 0.2444 - val_accuracy: 0.9048 - lr: 2.0000e-04\n",
      "Epoch 21/250\n",
      "720/720 [==============================] - 168s 232ms/step - loss: 0.3111 - accuracy: 0.8845 - val_loss: 0.2380 - val_accuracy: 0.9098 - lr: 2.0000e-04\n",
      "Epoch 22/250\n",
      "720/720 [==============================] - 167s 232ms/step - loss: 0.3099 - accuracy: 0.8853 - val_loss: 0.2320 - val_accuracy: 0.9109 - lr: 2.0000e-04\n",
      "Epoch 23/250\n",
      "720/720 [==============================] - 168s 233ms/step - loss: 0.3047 - accuracy: 0.8860 - val_loss: 0.2356 - val_accuracy: 0.9051 - lr: 2.0000e-04\n",
      "Epoch 24/250\n",
      "720/720 [==============================] - 169s 234ms/step - loss: 0.3007 - accuracy: 0.8881 - val_loss: 0.2504 - val_accuracy: 0.8984 - lr: 2.0000e-04\n",
      "Epoch 25/250\n",
      "720/720 [==============================] - 170s 235ms/step - loss: 0.3013 - accuracy: 0.8874 - val_loss: 0.2420 - val_accuracy: 0.9022 - lr: 2.0000e-04\n",
      "Epoch 26/250\n",
      "720/720 [==============================] - 171s 237ms/step - loss: 0.2995 - accuracy: 0.8871 - val_loss: 0.2354 - val_accuracy: 0.9062 - lr: 2.0000e-04\n",
      "Epoch 27/250\n",
      "720/720 [==============================] - 167s 231ms/step - loss: 0.3002 - accuracy: 0.8870 - val_loss: 0.2331 - val_accuracy: 0.9130 - lr: 2.0000e-04\n",
      "Epoch 28/250\n",
      "720/720 [==============================] - 167s 231ms/step - loss: 0.2896 - accuracy: 0.8896 - val_loss: 0.2273 - val_accuracy: 0.9100 - lr: 4.0000e-05\n",
      "Epoch 29/250\n",
      "720/720 [==============================] - 167s 231ms/step - loss: 0.2895 - accuracy: 0.8900 - val_loss: 0.2236 - val_accuracy: 0.9145 - lr: 4.0000e-05\n",
      "Epoch 30/250\n",
      "720/720 [==============================] - 169s 234ms/step - loss: 0.2933 - accuracy: 0.8888 - val_loss: 0.2233 - val_accuracy: 0.9138 - lr: 4.0000e-05\n",
      "Epoch 31/250\n",
      "720/720 [==============================] - 170s 236ms/step - loss: 0.2900 - accuracy: 0.8899 - val_loss: 0.2257 - val_accuracy: 0.9097 - lr: 4.0000e-05\n",
      "Epoch 32/250\n",
      "720/720 [==============================] - 170s 236ms/step - loss: 0.2891 - accuracy: 0.8898 - val_loss: 0.2217 - val_accuracy: 0.9137 - lr: 4.0000e-05\n",
      "Epoch 33/250\n",
      "720/720 [==============================] - 170s 235ms/step - loss: 0.2860 - accuracy: 0.8943 - val_loss: 0.2262 - val_accuracy: 0.9126 - lr: 4.0000e-05\n",
      "Epoch 34/250\n",
      "720/720 [==============================] - 170s 236ms/step - loss: 0.2845 - accuracy: 0.8960 - val_loss: 0.2224 - val_accuracy: 0.9128 - lr: 4.0000e-05\n",
      "Epoch 35/250\n",
      "720/720 [==============================] - 170s 237ms/step - loss: 0.2840 - accuracy: 0.8937 - val_loss: 0.2213 - val_accuracy: 0.9142 - lr: 4.0000e-05\n",
      "Epoch 36/250\n",
      "720/720 [==============================] - 169s 235ms/step - loss: 0.2882 - accuracy: 0.8901 - val_loss: 0.2258 - val_accuracy: 0.9107 - lr: 4.0000e-05\n",
      "Epoch 37/250\n",
      "720/720 [==============================] - 169s 234ms/step - loss: 0.2882 - accuracy: 0.8913 - val_loss: 0.2275 - val_accuracy: 0.9104 - lr: 4.0000e-05\n",
      "Epoch 38/250\n",
      "720/720 [==============================] - 167s 232ms/step - loss: 0.2825 - accuracy: 0.8941 - val_loss: 0.2286 - val_accuracy: 0.9100 - lr: 4.0000e-05\n",
      "Epoch 39/250\n",
      "720/720 [==============================] - 166s 230ms/step - loss: 0.2830 - accuracy: 0.8933 - val_loss: 0.2344 - val_accuracy: 0.9083 - lr: 4.0000e-05\n",
      "Epoch 40/250\n",
      "720/720 [==============================] - 167s 232ms/step - loss: 0.2854 - accuracy: 0.8927 - val_loss: 0.2262 - val_accuracy: 0.9107 - lr: 4.0000e-05\n",
      "Epoch 41/250\n",
      "720/720 [==============================] - 166s 231ms/step - loss: 0.2796 - accuracy: 0.8953 - val_loss: 0.2240 - val_accuracy: 0.9121 - lr: 8.0000e-06\n",
      "Epoch 42/250\n",
      "720/720 [==============================] - 165s 230ms/step - loss: 0.2841 - accuracy: 0.8919 - val_loss: 0.2235 - val_accuracy: 0.9131 - lr: 8.0000e-06\n",
      "Epoch 43/250\n",
      "720/720 [==============================] - 168s 232ms/step - loss: 0.2825 - accuracy: 0.8943 - val_loss: 0.2244 - val_accuracy: 0.9138 - lr: 8.0000e-06\n",
      "Epoch 44/250\n",
      "720/720 [==============================] - 168s 233ms/step - loss: 0.2832 - accuracy: 0.8940 - val_loss: 0.2248 - val_accuracy: 0.9124 - lr: 8.0000e-06\n",
      "Epoch 45/250\n",
      "720/720 [==============================] - 167s 232ms/step - loss: 0.2836 - accuracy: 0.8948 - val_loss: 0.2228 - val_accuracy: 0.9124 - lr: 8.0000e-06\n"
     ]
    }
   ],
   "source": [
    "history = cnn.fit(\n",
    "    train_set,\n",
    "    epochs=250,\n",
    "    validation_data=test_set,\n",
    "    callbacks=[checkpoint, early_stopping, reduce_lr,tensorboard_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "8caa749d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 33624), started 0:23:06 ago. (Use '!kill 33624' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-11d332d768206de9\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-11d332d768206de9\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir logs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "ab6f23f8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180/180 [==============================] - 10s 54ms/step - loss: 0.2213 - accuracy: 0.9142\n",
      "Test loss: 0.22126680612564087\n",
      "Test accuracy: 0.9141765236854553\n"
     ]
    }
   ],
   "source": [
    "evaluation = cnn.evaluate(test_set)\n",
    "\n",
    "# Print the loss and accuracy\n",
    "print(\"Test loss:\", evaluation[0])\n",
    "print(\"Test accuracy:\", evaluation[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "fb4dd69e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Validation Accuracy: 0.9145239591598511\n"
     ]
    }
   ],
   "source": [
    "best_val_accuracy = max(history.history['val_accuracy'])\n",
    "print(\"Best Validation Accuracy:\", best_val_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e27d0a93",
   "metadata": {
    "colab_type": "text",
    "id": "U3PZasO0006Z"
   },
   "source": [
    "## Part 4 - Making a single prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "9ede6890",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "best_model = load_model(\"best_model.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "9375626d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step\n",
      "Predicted class: Cigar-shaped smooth\n",
      "Prediction probabilities: [[5.5301964e-01 4.1012773e-01 7.4697056e-07 3.6497749e-02 3.5415587e-04]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "\n",
    "class_labels = ['Cigar-shaped smooth',   'In between smooth','completely round smooth','edge-on', 'spiral']\n",
    "\n",
    "path = \"Cigar-shaped smooth\"\n",
    "image_code = \"147305\"\n",
    "\n",
    "img_path = f\"Train_images/{path}/{image_code}.jpg\"\n",
    "\n",
    "\n",
    "img = image.load_img(img_path, target_size=(224, 224))\n",
    "img_array = image.img_to_array(img)\n",
    "img_array = np.expand_dims(img_array, axis=0)\n",
    "img_array = img_array / 255.0  # Normalize pixel values to [0, 1]\n",
    "\n",
    "predictions = best_model.predict(img_array)\n",
    "predicted_class_index = np.argmax(predictions)\n",
    "predicted_class_label = class_labels[predicted_class_index]\n",
    "\n",
    "print(\"Predicted class:\", predicted_class_label)\n",
    "print(\"Prediction probabilities:\", predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "9e1dae4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 13ms/step\n",
      "Predicted class: In between smooth\n",
      "Prediction probabilities: [[1.3218604e-01 6.7485460e-05 1.7512243e-10 8.5531127e-01 1.2435321e-02]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "# Load your trained model\n",
    "model = cnn  # Load your model here\n",
    "\n",
    "# Load an image for prediction\n",
    "path = \"edge-on\"\n",
    "image_code = \"101232\"\n",
    "\n",
    "img_path = f\"Train_images/{path}/{image_code}.jpg\"\n",
    "img = image.load_img(img_path, target_size=(224, 224))\n",
    "img_array = image.img_to_array(img)\n",
    "img_array = np.expand_dims(img_array, axis=0)\n",
    "\n",
    "# Preprocess the image\n",
    "img_array = img_array / 255.0  # Normalize pixel values to [0, 1]\n",
    "\n",
    "# Make a prediction\n",
    "predictions = model.predict(img_array)\n",
    "\n",
    "# Convert predictions to class labels\n",
    "\n",
    "predicted_class_index = np.argmax(predictions)\n",
    "predicted_class_label = class_labels[predicted_class_index]\n",
    "\n",
    "print(\"Predicted class:\", predicted_class_label)\n",
    "print(\"Prediction probabilities:\", predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "7446fb45",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gsSiWEJY1BPB"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 12ms/step\n",
      "[0. 0. 0. 0. 1.]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing import image\n",
    "test_image = image.load_img('Train_images/spiral/100951.jpg', target_size = (224, 224))\n",
    "test_image = image.img_to_array(test_image)\n",
    "test_image = np.expand_dims(test_image, axis = 0)\n",
    "result = cnn.predict(test_image)\n",
    "train_set.class_indices\n",
    "if result[0][0] == 1:\n",
    "  prediction = 'Cigar-shaped smooth'\n",
    "elif result[0][1] ==1:\n",
    "  prediction = 'completely round smooth'\n",
    "elif result[0][2] ==1:\n",
    "  prediction = 'edge-on'\n",
    "elif result[0][3] ==1:\n",
    "  prediction = 'In between smooth'\n",
    "else:\n",
    "  prediction = 'spiral'\n",
    "\n",
    "print(result[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "cd6ab493",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ED9KB3I54c1i"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spiral\n"
     ]
    }
   ],
   "source": [
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00aec7d5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
